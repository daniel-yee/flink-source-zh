### FlinkKafkaConsumer

FlinkKafkaConsumer是一个流式数据源，用于从Apache Kafka中获取并行数据流。其继承结构如下图所示：
![FlinkKafkaConsumer继承体系](../images/flinkkafka.png "FlinkKafkaConsumer继承体系")

从上图可以看到，FlinkKafkaConsumer继承于FlinkKafkaConsumerBase类，而FlinkKafkaConsumerBase类又实现了RichFunction接口和SourceFunction
接口(在Flink 1.11版本中进行了重构，实现的是ParallelSourceFunction接口)。由于实现了RichFunction接口，所以我们可以分析下其open()方法和run()
方法。

open()方法的实现在FlinkKafkaConsumerBase类中，主要是FlinkKafkaConsumer的初始化逻辑。
首先设置offset的提交模式，OffsetCommitMode是一个枚举类型，有以下三个取值：
  * DISABLED：完全禁用offset的提交;
  * ON_CHECKPOINTS：仅在checkpoint完成时提交offset;
  * KAFKA_PERIODIC：周期性提交，使用kafka客户端内部的自动提交功能;
具体判断OffsetCommitMode的逻辑被封装在OffsetCommitModes.fromConfiguration()方法中，该方法会先判断是否启用checkpoint，如果启用且同时启用
了checkpoint完成时提交offset，则返回ON_CHECKPOINTS；如果未启用checkpoint，同时启用了自动提交则返回KAFKA_PERIODIC，否则在
其他情况下都返回DISABLED。
接着便是创建和启动分区发现工具。createPartitionDiscoverer()方法创建了一个AbstractPartitionDiscoverer类的实例partitionDiscoverer，主要
用于kafka分区的发现，其中的参数topicsDescriptor描述了consumer根据什么样的规则订阅kafka的topic，有两种规则：一种是topic名称的固定列表fixedTopics，
另一种是匹配topic名称的正则表达式topicPattern。partitionDiscoverer.open()方法打开了kafka分区发现，并初始化所有需要的kafka连接。

初始化subscribedPartitionsToStartOffsets已订阅的分区列表，它被初始化为一个hashmap。
partitionDiscoverer.discoverPartitions()方法用于获取所有fixedTopics和匹配topicPattern的topic包含的所有分区信息。

接下来的逻辑分为两个部分，如果consumer是从快照恢复的，则走快照恢复逻辑，否则走直接启动逻辑。
先分析从快照恢复的逻辑，既然是从快照恢复的，那么restoredState肯定不为空，否则就会为空。如果restoredState中没有某个分区的状态，那么将直接从最早
的位点开始消费(这个逻辑是写死的，一定要注意)。
然后对subscribedPartitionsToStartOffsets赋值，它会过滤掉不归该task负责的kafka分区后，将剩余的分区和位点信息放入已订阅的分区列表。然后，判断
是否需要依照分区发现配置的topic正则表达式过滤分区，如果是的话就会过滤掉topic名称不符合topicPattern的分区。

如果consumer不是从快照恢复的，那么restoredState就会为空，consumer就会直接启动，会根据startupMode启动模式走不同的启动逻辑。它也是一个枚举类
型，有五个枚举值：
  * GROUP_OFFSETS：从保存在zookeeper或者是Kafka broker的对应消费者组提交的offset开始消费，这是默认的配置;
  * EARLIEST：尽可能从最早的offset开始消费;
  * LATEST：从最近的offset开始消费;
  * TIMESTAMP：从用户提供的timestamp处开始消费;
  * SPECIFIC_OFFSETS：从用户提供的offset处开始消费。
consumer使用分区发现获取初始分区后，根据StartupMode来设置消费的起始offset。先来看SPECIFIC_OFFSETS的情况，在此种情况下，如果没有配置具体的
消费位点，将会直接抛出异常。否则，获取每个分区指定的消费起始offset，如果该分区设置了消费起始的offset，则从设置的offset开始消费，否则从消费者所
属的消费组的位点开始消费。如果采用TIMESTAMP模式，则会在没有配置消费起始timestamp时抛出异常。否则根据timestamp的值获取到对应的offset，并判断
获取到的offset是否为空，如果不为空就从offset开始消费，否则就从最近的offset开始消费。

再来看run()方法，其实现同样是在FlinkKafkaConsumerBase类中。
   
